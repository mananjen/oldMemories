{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "from realesrgan import RealESRGANer\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import transforms\n",
    "from basicsr.archs.swinir_arch import SwinIR\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] = r\"C:\\ffmpeg\\ffmpeg-7.1-full_build\\bin\" + \";\" + os.environ[\"PATH\"]\n",
    "# rife_path = r\"D:\\oldMemories\\RIFE\"\n",
    "# sys.path.append(rife_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the source folder to traverse\n",
    "SOURCE_FOLDER = r\"F:\\consolidated old photos\"\n",
    "\n",
    "# Define the output folder for converted videos (change if needed)\n",
    "OUTPUT_FOLDER = r\"F:\\consolidated old photos\\converted_videos\"\n",
    "\n",
    "# Test data\n",
    "TEST_SOURCE_FOLDER = r\"D:\\oldMemoriesTestArea\"\n",
    "TEST_OUTPUT_FOLDER = r\"D:\\oldMemoriesTestArea\\converted_videos\"\n",
    "TEST_EXTRACTS_FOLDER = r\"D:\\oldMemoriesTestArea\\extracts\"\n",
    "TEST_SWINIR_FOLDER = r\"D:\\oldMemoriesTestArea\\swinir\"\n",
    "TEST_UPSCALED_FOLDER = r\"D:\\oldMemoriesTestArea\\upscaled\"\n",
    "FINAL_VIDEO_FOLDER = r\"D:\\oldMemoriesTestArea\\final_videos\"\n",
    "\n",
    "# real esrgan model\n",
    "REALESRGAN_MODEL_PATH = r\"D:\\oldMemories\\RealESRGAN_x4plus.pth\"\n",
    "SWINIR_MODEL_PATH = r\"D:\\oldMemories\\005_colorDN_DFWB_s128w8_SwinIR-M_noise15.pth\"\n",
    "\n",
    "RIFE_SCRIPT = r\"D:\\oldMemories\\RIFE\\inference_video.py\"\n",
    "\n",
    "# Video extensions that need standardizing\n",
    "TARGET_EXTENSIONS = {\".avi\", \".dat\", \".mpg\", \".vob\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info on the video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_formats_and_paths(folder_path):\n",
    "    \"\"\"\n",
    "    Traverse all subfolders, count video file formats, and list paths for each format.\n",
    "\n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder to scan.\n",
    "\n",
    "    Returns:\n",
    "    - Dict with formats as keys, and a tuple (count, list of paths) as values.\n",
    "    \"\"\"\n",
    "    # Define common video file extensions\n",
    "    video_extensions = {\n",
    "        \".mp4\", \".avi\", \".mkv\", \".mov\", \".wmv\", \".flv\", \".webm\", \".mpeg\", \".3gp\", \".mpg\", \".m4v\", \".vob\", \".dat\"\n",
    "    }\n",
    "\n",
    "    # Dictionary to store format counts and paths\n",
    "    format_data = defaultdict(lambda: {\"count\": 0, \"paths\": []})\n",
    "\n",
    "    # Walk through the folder and its subfolders\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            _, ext = os.path.splitext(file)\n",
    "            ext = ext.lower()\n",
    "            if ext in video_extensions:\n",
    "                full_path = os.path.join(root, file)\n",
    "                format_data[ext][\"count\"] += 1\n",
    "                format_data[ext][\"paths\"].append(full_path)\n",
    "\n",
    "    return dict(format_data)\n",
    "\n",
    "# Example usage\n",
    "checkVideoFormatsHere = r\"F:\\consolidated old photos\"  # Replace with your folder path\n",
    "video_format_data = get_video_formats_and_paths(checkVideoFormatsHere)\n",
    "\n",
    "# Print results\n",
    "print(f\"Video formats and their counts/paths in '{checkVideoFormatsHere}':\\n\")\n",
    "for format, data in sorted(video_format_data.items()):\n",
    "    print(f\"Format: {format}\")\n",
    "    print(f\"Count: {data['count']}\")\n",
    "    # if count < 5 print their paths else print only the count\n",
    "    if data['count'] < 5:\n",
    "        print(\"Paths:\")\n",
    "        for path in data[\"paths\"]:\n",
    "            print(f\"  {path}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization of video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_videos(source_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Traverse all subfolders from source_folder, find target video formats,\n",
    "    and convert them to MP4 (H.264 + AAC) in output_folder, mirroring the folder structure.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(source_folder):\n",
    "        for file_name in files:\n",
    "            # Get file extension in lowercase\n",
    "            _, ext = os.path.splitext(file_name)\n",
    "            ext = ext.lower()\n",
    "\n",
    "            # If it's one of the target video formats, convert it\n",
    "            if ext in TARGET_EXTENSIONS:\n",
    "                source_file_path = os.path.join(root, file_name)\n",
    "\n",
    "                # Build the mirrored output path by replacing SOURCE_FOLDER with OUTPUT_FOLDER\n",
    "                relative_path = os.path.relpath(root, source_folder)\n",
    "                output_subfolder = os.path.join(output_folder, relative_path)\n",
    "                os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "                # Construct output filename (e.g., \"Video 4_converted.mp4\")\n",
    "                base_name = os.path.splitext(file_name)[0]\n",
    "                output_file_path = os.path.join(output_subfolder, base_name + \".mp4\")\n",
    "\n",
    "                print(f\"\\nConverting: {source_file_path}\\n   to --> {output_file_path}\")\n",
    "\n",
    "                # ffmpeg command to convert video to H.264 (libx264) and AAC\n",
    "                command = [\n",
    "                    \"ffmpeg\",\n",
    "                    \"-y\",\n",
    "                    \"-i\", source_file_path,\n",
    "                    \"-c:v\", \"libx264\",\n",
    "                    \"-crf\", \"15\",        # Lower = higher quality, bigger file\n",
    "                    \"-preset\", \"slow\",   # Or 'medium' / 'slower' / 'veryslow'\n",
    "                    \"-c:a\", \"aac\",       # Encode audio with AAC\n",
    "                    \"-b:a\", \"192k\",      # Optional: set audio bitrate\n",
    "                    \"-movflags\", \"+faststart\",\n",
    "                    output_file_path\n",
    "                ]\n",
    "\n",
    "                try:\n",
    "                    subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "                    print(\"Conversion successful.\")\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"Error converting {source_file_path}.\\nFFmpeg error: {e.stderr.decode('utf-8', errors='replace')}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Make sure output folder exists\n",
    "    os.makedirs(TEST_OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "    standardize_videos(TEST_SOURCE_FOLDER, TEST_OUTPUT_FOLDER)\n",
    "    print(\"\\nAll possible videos have been processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_ffmpeg(input_video_path, output_audio_path):\n",
    "    \"\"\"\n",
    "    Extracts the audio track from a video using FFmpeg without re-encoding the audio.\n",
    "    -i <input_video>  : Input video file\n",
    "    -vn               : Disable video\n",
    "    -acodec copy      : Copy the existing audio track directly\n",
    "    \n",
    "    Args:\n",
    "        input_video_path  (str): Path to the input video (e.g., .mp4)\n",
    "        output_audio_path (str): Path to save the output audio file (e.g., .aac or .mp3)\n",
    "    \"\"\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",               # Overwrite output if it exists\n",
    "        \"-i\", input_video_path,\n",
    "        \"-vn\",             # No video\n",
    "        \"-acodec\", \"copy\", # Copy original audio track without re-encoding\n",
    "        output_audio_path\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(f\"Audio extracted to: {output_audio_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error extracting audio from {input_video_path}.\\nFFmpeg error: {e.stderr.decode('utf-8', errors='replace')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_opencv(input_video_path, frames_output_folder):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video using OpenCV and saves them as PNG files.\n",
    "    Args:\n",
    "        input_video_path     (str): Path to the input .mp4 (or other) video.\n",
    "        frames_output_folder (str): Folder to save extracted frames.\n",
    "    \"\"\"\n",
    "    os.makedirs(frames_output_folder, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frame_filename = os.path.join(frames_output_folder, f\"frame_{frame_count:06d}.png\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"Extracted {frame_count} frames from {input_video_path} to {frames_output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_standardized_videos(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Traverse all subfolders in `input_folder` to find .mp4 files.\n",
    "    For each video, extract audio + frames in the corresponding subfolder of `output_folder`.\n",
    "    \n",
    "    Args:\n",
    "        input_folder  (str): Path with standardized videos (likely .mp4).\n",
    "        output_folder (str): Path to store extracted audio and frames.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file_name in files:\n",
    "            if file_name.lower().endswith(\".mp4\"):\n",
    "                video_path = os.path.join(root, file_name)\n",
    "\n",
    "                # Mirror subfolder structure under output_folder\n",
    "                relative_path = os.path.relpath(root, input_folder)\n",
    "                target_subfolder = os.path.join(output_folder, relative_path)\n",
    "                os.makedirs(target_subfolder, exist_ok=True)\n",
    "\n",
    "                # Derive base name (no extension)\n",
    "                base_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "                # 1) Extract Audio\n",
    "                # We'll name the audio file base_name.aac in this example\n",
    "                audio_file_path = os.path.join(target_subfolder, base_name + \".aac\")\n",
    "                extract_audio_ffmpeg(video_path, audio_file_path)\n",
    "\n",
    "                # 2) Extract Frames\n",
    "                frames_folder = os.path.join(target_subfolder, f\"{base_name}_frames\")\n",
    "                extract_frames_opencv(video_path, frames_folder)\n",
    "\n",
    "    print(\"All videos have been processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure output folder exists\n",
    "os.makedirs(TEST_EXTRACTS_FOLDER, exist_ok=True)\n",
    "process_standardized_videos(TEST_OUTPUT_FOLDER, TEST_EXTRACTS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising and sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SwinIR model for denoising\n",
    "def load_swinir_model(model_path, device):\n",
    "    model = SwinIR(\n",
    "        upscale=1,\n",
    "        in_chans=3,\n",
    "        img_size=128,\n",
    "        window_size=8,\n",
    "        img_range=1.0,\n",
    "        depths=[6, 6, 6, 6, 6, 6],\n",
    "        embed_dim=180,\n",
    "        num_heads=[6, 6, 6, 6, 6, 6],\n",
    "        mlp_ratio=2,\n",
    "        upsampler='',\n",
    "        resi_connection='1conv'\n",
    "    )\n",
    "    \n",
    "    # Load weights\n",
    "    pretrained = torch.load(model_path, map_location=device)\n",
    "    param_key_g = 'params' if 'params' in pretrained else list(pretrained.keys())[0]  # Handle different model keys\n",
    "    model.load_state_dict(pretrained[param_key_g], strict=True)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = load_swinir_model(SWINIR_MODEL_PATH, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_image_swinir(model, image_path, device):\n",
    "    \"\"\" Denoise an image using SwinIR and return the output image. \"\"\"\n",
    "    # Load and convert image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "\n",
    "    # Pad image to be a multiple of window size (8)\n",
    "    h, w, c = img.shape\n",
    "    h_pad = (8 - h % 8) % 8\n",
    "    w_pad = (8 - w % 8) % 8\n",
    "    img = np.pad(img, ((0, h_pad), (0, w_pad), (0, 0)), 'reflect')\n",
    "\n",
    "    # Convert to tensor\n",
    "    img_tensor = torch.from_numpy(np.transpose(img, (2, 0, 1))).float().unsqueeze(0).to(device)\n",
    "\n",
    "    # Run SwinIR model\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor).clamp_(0, 1)  # Clamp values to valid range\n",
    "\n",
    "    # Convert back to image\n",
    "    output = output.squeeze().cpu().numpy().transpose(1, 2, 0)  # CHW → HWC\n",
    "    output = (output[:h, :w] * 255.0).astype(np.uint8)  # Remove padding & scale back to [0,255]\n",
    "\n",
    "    return cv2.cvtColor(output, cv2.COLOR_RGB2BGR)  # Convert back to BGR for OpenCV saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image_opencv(image):\n",
    "    \"\"\"Apply sharpening filter using OpenCV.\"\"\"\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1,  5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened\n",
    "\n",
    "def sharpen_image_pil(image):\n",
    "    \"\"\"Apply unsharp mask using PIL for natural sharpening.\"\"\"\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    sharpened = pil_image.filter(ImageFilter.UnsharpMask(radius=2, percent=150, threshold=3))\n",
    "    return cv2.cvtColor(np.array(sharpened), cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_images(input_dir, output_dir, model, device):\n",
    "#     \"\"\" Recursively denoise images while maintaining folder structure. \"\"\"\n",
    "#     input_path = Path(input_dir)\n",
    "#     output_path = Path(output_dir)\n",
    "\n",
    "#     for img_path in input_path.rglob('*'):\n",
    "#         if img_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.bmp']:\n",
    "#             relative_path = img_path.relative_to(input_path)\n",
    "#             target_path = output_path / relative_path\n",
    "#             target_path.parent.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "#             # Apply denoising\n",
    "#             denoised_img = denoise_image_swinir(model, img_path, device)\n",
    "#             cv2.imwrite(str(target_path), denoised_img)  # Save output\n",
    "#             print(f\"Denoised and saved: {target_path}\")\n",
    "\n",
    "def process_images_with_sharpening(input_dir, output_dir, model, device, sharpening_method=\"opencv\"):\n",
    "    \"\"\"Denoise images and apply sharpening while maintaining folder structure.\"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "\n",
    "    for img_path in input_path.rglob('*'):\n",
    "        if img_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.bmp']:\n",
    "            relative_path = img_path.relative_to(input_path)\n",
    "            target_path = output_path / relative_path\n",
    "            target_path.parent.mkdir(parents=True, exist_ok=True)  # Ensure folder exists\n",
    "\n",
    "            # Apply denoising\n",
    "            denoised_img = denoise_image_swinir(model, img_path, device)\n",
    "\n",
    "            # Apply sharpening\n",
    "            if sharpening_method == \"opencv\":\n",
    "                final_img = sharpen_image_opencv(denoised_img)\n",
    "            else:\n",
    "                final_img = sharpen_image_pil(denoised_img)\n",
    "\n",
    "            # Save final output\n",
    "            cv2.imwrite(str(target_path), final_img)\n",
    "            print(f\"Denoised, sharpened, and saved: {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(TEST_SWINIR_FOLDER, exist_ok=True)\n",
    "\n",
    "# Run batch processing\n",
    "# process_images_with_sharpening(TEST_EXTRACTS_FOLDER, TEST_SWINIR_FOLDER, model, device, sharpening_method=\"opencv\")\n",
    "process_images_with_sharpening(TEST_EXTRACTS_FOLDER, TEST_SWINIR_FOLDER, model, device, sharpening_method=\"pil\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_extracted_frames_official(\n",
    "    input_folder,\n",
    "    output_folder,\n",
    "    realesrgan_model_path,\n",
    "    scale=4\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursively upscale extracted frames in input_folder using the official Real-ESRGAN approach.\n",
    "    Saves upscaled frames to the corresponding structure in output_folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1) Define the architecture that matches your .pth file\n",
    "    model = RRDBNet(\n",
    "        num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=scale\n",
    "    )\n",
    "    \n",
    "    # 2) Create RealESRGANer, passing the custom model\n",
    "    upsampler = RealESRGANer(\n",
    "        scale=scale,\n",
    "        model_path=realesrgan_model_path,\n",
    "        model=model,          # ← provide the RRDBNet model\n",
    "        tile=0,               # 0 = no tiling (set larger tile if you run out of memory)\n",
    "        tile_pad=10,\n",
    "        pre_pad=0,\n",
    "        half=False,           # if you have low VRAM, try True\n",
    "        gpu_id=0\n",
    "    )\n",
    "\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file_name in files:\n",
    "            # Check if this is an image\n",
    "            if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                input_path = os.path.join(root, file_name)\n",
    "                rel_path = os.path.relpath(root, input_folder)\n",
    "                target_subfolder = os.path.join(output_folder, rel_path)\n",
    "                os.makedirs(target_subfolder, exist_ok=True)\n",
    "\n",
    "                output_path = os.path.join(target_subfolder, file_name)\n",
    "                img = cv2.imread(input_path, cv2.IMREAD_COLOR)\n",
    "                if img is None:\n",
    "                    print(f\"Warning: Could not read {input_path}. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Upscale\n",
    "                output, _ = upsampler.enhance(img, outscale=scale)\n",
    "                cv2.imwrite(output_path, output)\n",
    "\n",
    "    print(\"All frames have been upscaled!\")\n",
    "\n",
    "os.makedirs(TEST_UPSCALED_FOLDER, exist_ok=True)\n",
    "\n",
    "upscale_extracted_frames_official(\n",
    "    input_folder=TEST_SWINIR_FOLDER,\n",
    "    output_folder=TEST_UPSCALED_FOLDER,\n",
    "    realesrgan_model_path=REALESRGAN_MODEL_PATH,\n",
    "    scale=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReStitching the video back together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure final output folder exists\n",
    "os.makedirs(FINAL_VIDEO_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_fps(video_path):\n",
    "    \"\"\" Extract FPS from the original video using FFmpeg. \"\"\"\n",
    "    try:\n",
    "        cmd = f'ffmpeg -i \"{video_path}\"'\n",
    "        output = subprocess.run(cmd, shell=True, capture_output=True, text=True).stderr  # Get stderr output\n",
    "\n",
    "        # Debugging: Print FFmpeg output\n",
    "        print(\"FFmpeg Output:\\n\", output)\n",
    "\n",
    "        # Extract FPS using regex\n",
    "        match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*fps', output)\n",
    "        if match:\n",
    "            fps = float(match.group(1))\n",
    "            print(f\"✅ Extracted FPS: {fps}\")\n",
    "            return fps\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ FFmpeg Error:\\n{e.stderr}\")\n",
    "\n",
    "    print(\"⚠ Warning: Could not detect FPS, using default 30 FPS.\")\n",
    "    return 30  # Fallback to 30 FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_to_video_with_audio(video_name):\n",
    "    \"\"\"Stitch frames into a video and add the original audio.\"\"\"\n",
    "    video_stem = Path(video_name).stem  # Extract \"flying car\" from \"flying car.mp4\"\n",
    "    frames_folder = Path(TEST_UPSCALED_FOLDER) / f\"{video_stem}_frames\"\n",
    "    original_video_path = Path(TEST_OUTPUT_FOLDER) / video_name\n",
    "    audio_file = Path(TEST_EXTRACTS_FOLDER) / f\"{video_stem}.aac\"\n",
    "    output_video = Path(FINAL_VIDEO_FOLDER) / f\"{video_stem}_final.mp4\"\n",
    "\n",
    "    # Extract original FPS\n",
    "    fps = get_video_fps(original_video_path)\n",
    "\n",
    "    # Ensure frames exist\n",
    "    if not frames_folder.exists() or not any(frames_folder.glob(\"*.png\")):\n",
    "        print(f\"❌ Frames folder is missing or empty: {frames_folder}\")\n",
    "        return\n",
    "\n",
    "    # FFmpeg command to stitch frames into a video\n",
    "    temp_video = Path(FINAL_VIDEO_FOLDER) / f\"{video_stem}_no_audio.mp4\"\n",
    "    cmd = f'ffmpeg -framerate {fps} -i \"{frames_folder}/frame_%06d.png\" -c:v libx264 -crf 0 -preset slow \"{temp_video}\"'\n",
    "    print(f\"Running FFmpeg command: {cmd}\")\n",
    "    subprocess.run(cmd, shell=True, check=True)\n",
    "\n",
    "    # If audio exists, merge it\n",
    "    if audio_file.exists():\n",
    "        cmd_audio = f'ffmpeg -i \"{temp_video}\" -i \"{audio_file}\" -c:v copy -c:a aac -b:a 256k \"{output_video}\"'\n",
    "        subprocess.run(cmd_audio, shell=True, check=True)\n",
    "        temp_video.unlink()  # Remove temp video without audio\n",
    "        print(f\"✅ Final video with audio saved: {output_video}\")\n",
    "    else:\n",
    "        print(f\"⚠ No audio found, saving video without audio: {temp_video}\")\n",
    "\n",
    "# Run the function\n",
    "frames_to_video_with_audio(\"flying car.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "old_mems",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
